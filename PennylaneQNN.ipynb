{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGOJl9cQzjNOfyEtOHNbgo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nibess1/QNNVis/blob/main/PennylaneQNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cVS3-CYhqZwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "08363242-1e4d-44ad-c6e6-029832ba9983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.36.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane)\n",
            "  Downloading autoray-0.6.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.3)\n",
            "Collecting pennylane-lightning>=0.36 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.2.2)\n",
            "Installing collected packages: appdirs, semantic-version, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.6.12 pennylane-0.36.0 pennylane-lightning-0.36.0 rustworkx-0.14.2 semantic-version-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer\n"
      ],
      "metadata": {
        "id": "OA6psWlwqc7c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is how to create a random circuit. Based on the seed, the circuit generated will always be constant. Increasing weights increases the number of parameters of circuit."
      ],
      "metadata": {
        "id": "oDqLp43aJQzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"default.qubit\", wires = 16)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(theta):\n",
        "  qml.PauliX(wires = 0)\n",
        "  qml.RY(theta, wires = 0)\n",
        "  qml.CNOT([0, 1])\n",
        "  return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliY(1))\n",
        "\n",
        "circuit(0.1)"
      ],
      "metadata": {
        "id": "SBkrVcQ1q0D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22de4a32-5917-4b34-9fe6-3f0794ed6627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.99500417, requires_grad=True), tensor(0., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "ImzobYaiubvq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihsZUTtovMPG",
        "outputId": "ab731bda-7a3d-4fcc-ab5d-9df1d6d7bedf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30   # Number of optimization epochs\n",
        "n_layers = 1    # Number of random layers\n",
        "n_train = 150    # Size of the train dataset\n",
        "n_test = 30     # Size of the test dataset\n",
        "\n",
        "# original [30 , 1 , 100, 30 ]\n",
        "# new model -> increased epochs to see if bigger improvements can be made\n",
        "# doubled train and test images to see if more samples will signiicantly improve performance.\n",
        "\n",
        "#modded to wd\n",
        "#SAVE_PATH = \"../_static/demonstration_assets/quanvolution/\"  # Data saving folder\n",
        "# SAVE_PATH = \"/content/_static/demonstration_assets/quanvolution\"\n",
        "SAVE_PATH = \"/content/\"\n",
        "\n",
        "PREPROCESS = False     # If False, skip quantum processing and load data from SAVE_PATH\n",
        "np.random.seed(0)     # Seed for NumPy random number generator\n",
        "tf.random.set_seed(0) # Seed for TensorFlow random number generator"
      ],
      "metadata": {
        "id": "7ZYLgs7RvYuQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images = train_images[:n_train]\n",
        "train_labels = train_labels[:n_train]\n",
        "test_images = test_images[:n_test]\n",
        "test_labels = test_labels[:n_test]\n",
        "\n",
        "\n",
        "\n",
        "# Normalize pixel values within 0 and 1\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "# Add extra dimension for convolution channels\n",
        "train_images = np.array(train_images[..., tf.newaxis], requires_grad=False) # note, requies_grad : BOOL = False is an adaptation of numpy made by pennylane.\n",
        "test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)   # normal numpy and numpy autograd both dont have this."
      ],
      "metadata": {
        "id": "57hZlgxrvN8N"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0].reshape(28,28)"
      ],
      "metadata": {
        "id": "PlSSDA0pw5yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1d6920a3-91ac-42d8-8065-41964200fae4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "         0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "         0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "         0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "         0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "         0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "         0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "         0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "         0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "         0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "         0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "         0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "         0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "         0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "         0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "         0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "         0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "         0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "         0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "         0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "         0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "         0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "         0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ]], requires_grad=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to downsample the image from 28 x 28 to 4x4. Then using 16 qubit simulation by performing angle encoding. An alternative solution might be to use angle encoding in the X,Y,Z plane of the bloch spehere, and lower the number of qubits required.\n",
        "\n",
        "Experiment 2: angle encoding of 6x6 downsample, with 12 qubits\n",
        "\n",
        "Experiment 3: angle encoding of 3x3 downsample, with 3 qubits"
      ],
      "metadata": {
        "id": "o_jFaz5yv5aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def downsample_image(image, new_size=(4, 4)):\n",
        "    \"\"\"\n",
        "    Downsamples a given 28x28 image to a specified size using average pooling.\n",
        "\n",
        "    Args:\n",
        "    image (np.array): A 28x28 numpy array representing the image.\n",
        "    new_size (tuple): The desired dimensions (height, width) of the downsampled image.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The downsampled image.\n",
        "    \"\"\"\n",
        "    # Calculate the size of the pooling window\n",
        "    height, width = image.shape\n",
        "    new_height, new_width = new_size\n",
        "    pool_height = height // new_height\n",
        "    pool_width = width // new_width\n",
        "\n",
        "    # Initialize the output image with zeros\n",
        "    downsampled = np.zeros(new_size, requires_grad = False)\n",
        "\n",
        "    # Loop over each block in the output image\n",
        "    for i in range(new_height):\n",
        "        for j in range(new_width):\n",
        "            # Calculate the starting and ending indices of the window\n",
        "            start_i = i * pool_height\n",
        "            end_i = start_i + pool_height\n",
        "            start_j = j * pool_width\n",
        "            end_j = start_j + pool_width\n",
        "\n",
        "            # Calculate the average of the current window\n",
        "            window = image[start_i:end_i, start_j:end_j]\n",
        "            downsampled[i, j] = np.mean(window)\n",
        "\n",
        "    return downsampled\n",
        "\n",
        "# Example usage:\n",
        "# Assuming `image` is a 28x28 numpy array representing an MNIST digit\n",
        "downsampled_image = downsample_image(train_images[2].reshape(28,28), (4,4))\n",
        "print(downsampled_image)\n",
        "img = np.reshape(downsampled_image, 16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWElGInSva1s",
        "outputId": "37c35da1-1382-45e3-b388-f4a822ebde48"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.01144458 0.         0.01496599 0.03921569]\n",
            " [0.24497799 0.         0.26706683 0.05106042]\n",
            " [0.1454982  0.22408964 0.38367347 0.        ]\n",
            " [0.         0.         0.17406963 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "qkeKQvYlxyzq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = 9\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax[0].imshow(train_images[img_num].reshape(28,28), cmap='gray', interpolation='nearest')\n",
        "ax[0].set_title('Original 28x28 Image')\n",
        "ax[0].axis('off')\n",
        "\n",
        "ax[1].imshow(downsample_image(train_images[img_num].reshape(28,28), (6,6)), cmap='gray', interpolation='nearest')\n",
        "ax[1].set_title('Downsampled 5x5 Image')\n",
        "ax[1].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "H9jtafDCxd0C",
        "outputId": "58606e1f-e4be-43d0-8fda-ce75e303a2f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am following a random guide I found online. They call each qubit and its tranformations wires.\n",
        "\n",
        "https://pennylane.ai/qml/demos/tutorial_variational_classifier/\n",
        "\n",
        "\\\n",
        "Here we initialise 4 wires, with a random rotation gate, and link each gate with a CNOT. 0-1, 1-2, 2-3, 3-0. Might experiment with different configurations later if i manage to get it working."
      ],
      "metadata": {
        "id": "pRaG5hrTbKYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device('default.qubit', wires=5)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def encode(feature_vector):\n",
        "    qml.AngleEmbedding(features=feature_vector[:5], wires=range(5), rotation='X')\n",
        "    qml.AngleEmbedding(features=feature_vector[5:10], wires=range(5), rotation='Y')\n",
        "    qml.AngleEmbedding(features=feature_vector[10:15], wires=range(5), rotation='Z')\n",
        "    qml.Hadamard(0)\n",
        "    return qml.probs(wires=range(4))"
      ],
      "metadata": {
        "id": "i856WF-da-Bw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(qml.draw(encode, expansion_strategy=\"device\")(img))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ytyBd7zKpp",
        "outputId": "6d2e95f6-0a64-4dd5-9573-acb4d119015f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: ──RX(0.01)──RY(0.00)──RZ(0.38)──H─┤ ╭Probs\n",
            "1: ──RX(0.00)──RY(0.27)──RZ(0.00)────┤ ├Probs\n",
            "2: ──RX(0.01)──RY(0.05)──RZ(0.00)────┤ ├Probs\n",
            "3: ──RX(0.04)──RY(0.15)──RZ(0.00)────┤ ╰Probs\n",
            "4: ──RX(0.24)──RY(0.22)──RZ(0.17)────┤       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoding is now completed. Now we need to pass on the quantum information into the ansatz. \\\n",
        "  1) Design an ansatz using random circuit \\\n",
        "  2) Somehow layer that\n",
        "  3) Pass in parameters"
      ],
      "metadata": {
        "id": "JlNxm5hH0bnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dev = qml.device(\"default.qubit\", wires=5)\n",
        "weights = np.zeros((15,1))\n",
        "\n",
        "def subroutine(weights):\n",
        "    qml.RandomLayers(weights=weights, wires=range(5))\n",
        "    return qml.expval(qml.Z(0))\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit1(weights):\n",
        "  qml.layer(subroutine(weights), 3)\n",
        "  return [qml.expval(qml.Z(0)), qml.expval(qml.Z(1))]\n",
        "\n",
        "\n",
        "print(qml.draw(circuit1, expansion_strategy=\"device\")(weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "K3vknNYi05Qg",
        "outputId": "9a7681c7-af54-4146-b400-19218b9c62f3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'ExpectationMP' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-94c6bcea0289>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/drawer/draw.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mexpansion_strategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"device\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expansion_strategy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"device\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         ):\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mprogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueuing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnnotatedQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qfunc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumScript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-94c6bcea0289>\u001b[0m in \u001b[0;36mcircuit1\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcircuit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubroutine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/templates/layer.py\u001b[0m in \u001b[0;36mlayer\u001b[0;34m(template, depth, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0marg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mtemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'ExpectationMP' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "state_prepartion(x) converts x into its quantum state.\n",
        "\n",
        "\\\n",
        "\n",
        "For example: 0101 becomes |0101>"
      ],
      "metadata": {
        "id": "zgJW4VnrbwXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def state_preparation(x):\n",
        "    qml.BasisState(x, wires=[0, 1, 2, 3])"
      ],
      "metadata": {
        "id": "EIM9KVMnboEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am guessing that the weights refer to the number of parameters that can be controlled for. The circuit would be constructed by the layer we defined earlier, which would be repeated for the number of parameters we want to control.\n",
        "\n",
        "__\n",
        "\n",
        "Do not know what `qml.expval(qml.PauliZ(0))` does."
      ],
      "metadata": {
        "id": "zGHh35iTcQtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev)\n",
        "def circuit(weights, x):\n",
        "    state_preparation(x)\n",
        "\n",
        "    for layer_weights in weights:\n",
        "        layer(layer_weights)\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "D4hqYsincOer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to add a “classical” bias parameter, the variational quantum classifier also needs some post-processing. We define the full model as a sum of the output of the quantum circuit, plus the trainable bias\n",
        "_____\n",
        "\\\n",
        "\n",
        "\n",
        "Neural networks typically have weights and biases. We are adding a classical bias instead of a quantum one. Not sure why."
      ],
      "metadata": {
        "id": "WxdeBEcCdSTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias"
      ],
      "metadata": {
        "id": "LZCGDvmHdQUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In supervised learning, the cost function is usually the sum of a loss function and a regularizer. We restrict ourselves to the standard square loss that measures the distance between target labels and model predictions.\n",
        "\n",
        "\\\n",
        "\n",
        "To monitor how many inputs the current classifier predicted correctly, we also define the accuracy, or the proportion of predictions that agree with a set of target labels."
      ],
      "metadata": {
        "id": "4To5uJIPdspe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(labels, predictions):\n",
        "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
        "    return np.mean((labels - qml.math.stack(predictions)) ** 2)"
      ],
      "metadata": {
        "id": "5UMksZ8KdtWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(labels, predictions):\n",
        "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
        "    acc = acc / len(labels)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "Ex1Ijjnmguyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the square loss function to return the cost of our predictions"
      ],
      "metadata": {
        "id": "eTnHzJA_hFDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)"
      ],
      "metadata": {
        "id": "jdH5LhoYhJ2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}